# DooDates - StratÃ©gie de Tests AutomatisÃ©s ComplÃ¨te

## ğŸ¯ Objectif : Tests 100% AutomatisÃ©s

> Mise Ã  jour 2025-08-26 â€” RÃ©fÃ©rence actuelle
> **Vision :** Aucun code ne passe en production sans validation automatique complÃ¨te.
> **Principe :** Fail Fast, Fix Fast - DÃ©tection immÃ©diate des rÃ©gressions.

- Workflows actifs (rÃ©fÃ©rences exactes dans `.github/workflows/`):
  - `pr-validation.yml`
  - `gemini-tests.yml`
  - `nightly-e2e.yml`
  - `notify-nightly-failure.yml`
  - `production-deploy-fixed.yml`
- Scripts de tests disponibles (extraits de `package.json`):
  - Jest: `test`, `test:watch`, `test:gemini`, `test:gemini:quick`, `test:gemini:production`
  - Vitest: `test:unit`, `test:unit:fast`, `test:unit:watch`, `test:unit:coverage`, `test:integration`, `test:ux-regression`
  - Playwright: `test:e2e`, `test:e2e:ui`, `test:e2e:headed`
  - Utilitaires: `type-check`, `lint:fix`, `format`, `format:check`, `validate:e2e`

Les sections ci-dessous dÃ©crivant d'autres workflows/tests non listÃ©s ci-dessus sont Ã  considÃ©rer comme Â« Planned Â» et pourront Ãªtre activÃ©es ultÃ©rieurement.

---

## ğŸ”„ StratÃ©gie Multi-Niveaux

### 1. ğŸ’» **Tests Locaux (DÃ©veloppement)**

#### Hook Pre-Commit (Obligatoire)

```bash
# .husky/pre-commit - S'exÃ©cute avant chaque commit
#!/bin/sh
echo "ğŸ” DooDates - Validation pre-commit..."

# Mode rapide optionnel pour accÃ©lÃ©rer les commits locaux
# Activez-le avec FAST_HOOKS=1 pour ignorer les vÃ©rifications lourdes
if [ "$FAST_HOOKS" = "1" ]; then
  echo "âš¡ Mode rapide activÃ© (FAST_HOOKS=1) - tests lourds ignorÃ©s"
  echo "ğŸ§ª Tests unitaires rapides..."
  npm run test:unit:fast
  if [ $? -ne 0 ]; then
    echo "âŒ Tests unitaires Ã©chouÃ©s - Commit bloquÃ©"
    exit 1
  fi

  echo "ğŸ’… Formatage du code..."
  npm run format

  echo "âœ… Pre-commit (rapide) validÃ© - Commit autorisÃ©"
  exit 0
fi

# 1. Tests unitaires rapides (< 30s)
echo "ğŸ§ª Tests unitaires rapides..."
npm run test:unit:fast
if [ $? -ne 0 ]; then
  echo "âŒ Tests unitaires Ã©chouÃ©s - Commit bloquÃ©"
  exit 1
fi

# 2. Validation TypeScript
echo "ğŸ” VÃ©rification TypeScript..."
npm run type-check
if [ $? -ne 0 ]; then
  echo "âŒ Erreurs TypeScript - Commit bloquÃ©"
  exit 1
fi

# 3. Tests UX RÃ©gression (critique)
echo "ğŸ¨ Tests UX RÃ©gression..."
npm run test:ux-regression
if [ $? -ne 0 ]; then
  echo "âŒ RÃ©gression UX dÃ©tectÃ©e - Commit bloquÃ©"
  exit 1
fi

# 4. Tests d'intÃ©gration
echo "ğŸ”— Tests d'intÃ©gration..."
npm run test:integration
if [ $? -ne 0 ]; then
  echo "âŒ Tests d'intÃ©gration Ã©chouÃ©s - Commit bloquÃ©"
  exit 1
fi

# 5. Formatage automatique
echo "ğŸ’… Formatage du code..."
npm run format

echo "âœ… Pre-commit validÃ© - Commit autorisÃ©"
```

#### Hook Pre-Push (Validation complÃ¨te)

```bash
# .husky/pre-push - S'exÃ©cute avant chaque push
#!/bin/sh
echo "ğŸš€ DooDates - Validation pre-push..."

# Ressources accrues pour Ã©viter OOM et fiabiliser Vitest
export NODE_OPTIONS="--max-old-space-size=4096"
export VITEST_MAX_THREADS=1
export VITEST_POOL=forks

# 1. Suite complÃ¨te de tests unitaires
echo "ğŸ§ª Tests unitaires complets..."
npm run test:unit
if [ $? -ne 0 ]; then
  echo "âŒ Tests unitaires complets Ã©chouÃ©s - Push bloquÃ©"
  exit 1
fi

# 2. Tests d'intÃ©gration
echo "ğŸ”— Tests d'intÃ©gration..."
npm run test:integration
if [ $? -ne 0 ]; then
  echo "âŒ Tests d'intÃ©gration Ã©chouÃ©s - Push bloquÃ©"
  exit 1
fi

# 3. Build de production
echo "ğŸ—ï¸ Build production..."
npm run build
if [ $? -ne 0 ]; then
  echo "âŒ Build production Ã©chouÃ© - Push bloquÃ©"
  exit 1
fi

echo "âœ… Pre-push validÃ© - Push autorisÃ©"
```

### 2. ğŸŒ **Tests GitHub (CI/CD)**

#### A. Pull Request (Validation ComplÃ¨te)

```yaml
# .github/workflows/pr-validation.yml
name: ğŸ” PR Validation
on:
  pull_request:
    branches: [main, develop]

jobs:
  # Job 1: Tests Rapides (ParallÃ¨le)
  quick-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        test-type: [unit, integration, ux-regression]
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node.js 20
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install dependencies
        run: npm ci

      - name: Run ${{ matrix.test-type }} tests
        run: npm run test:${{ matrix.test-type }}

      - name: Upload test results
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ matrix.test-type }}
          path: test-results/

  # Job 2: Tests IA (Critique)
  ai-validation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node.js 20
        uses: actions/setup-node@v4

      - name: Install dependencies
        run: npm ci

      - name: Run AI Tests (Quick)
        run: npm run test:gemini:quick
        env:
          VITE_GEMINI_API_KEY: ${{ secrets.VITE_GEMINI_API_KEY }}

      - name: Validate AI Performance
        run: |
          SCORE=$(node -e "
            const report = require('./tests/reports/quick-report.json');
            console.log(report.percentage);
          ")
          echo "Score IA: $SCORE%"
          if (( $(echo "$SCORE < 70" | bc -l) )); then
            echo "âŒ Performance IA insuffisante: $SCORE%"
            exit 1
          fi
          echo "âœ… Performance IA validÃ©e: $SCORE%"

  # Job 3: Build & Deploy Preview
  build-preview:
    needs: [quick-tests, ai-validation]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node.js 20
        uses: actions/setup-node@v4

      - name: Install dependencies
        run: npm ci

      - name: Build production
        run: npm run build

      - name: Deploy to Vercel Preview
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.ORG_ID }}
          vercel-project-id: ${{ secrets.PROJECT_ID }}
          scope: ${{ secrets.TEAM_ID }}

      - name: Comment PR with preview link
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: 'ğŸš€ Preview dÃ©ployÃ©: https://doodates-pr-${{ github.event.number }}.vercel.app'
            })
```

#### B. Push sur Main (DÃ©ploiement Production)

```yaml
# .github/workflows/production-deploy.yml
name: ğŸš€ Production Deploy
on:
  push:
    branches: [main]

jobs:
  # Job 1: Quality Gates (Bloquants)
  quality-gates:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node.js 20
        uses: actions/setup-node@v4

      - name: Install dependencies
        run: npm ci

      # Gate 1: Tests complets
      - name: "Gate 1: Tests Unitaires"
        run: npm run test:unit

      - name: "Gate 1: Tests IntÃ©gration"
        run: npm run test:integration

      - name: "Gate 1: Tests UX RÃ©gression"
        run: npm run test:ux-regression

      # Gate 2: Performance IA
      - name: "Gate 2: Tests IA Complets"
        run: npm run test:gemini:production
        env:
          VITE_GEMINI_API_KEY: ${{ secrets.VITE_GEMINI_API_KEY }}
        timeout-minutes: 30

      - name: "Gate 2: Validation Score IA"
        run: |
          SCORE=$(node -e "
            const report = require('./tests/reports/gemini-test-report.json');
            console.log(report.globalScore.percentage);
          ")
          echo "Score IA Production: $SCORE%"
          if (( $(echo "$SCORE < 95" | bc -l) )); then
            echo "âŒ Score IA insuffisant pour production: $SCORE%"
            echo "Minimum requis: 95%"
            exit 1
          fi
          echo "âœ… Score IA validÃ© pour production: $SCORE%"

      # Gate 3: Build Production
      - name: "Gate 3: Build Production"
        run: npm run build

      - name: "Gate 3: Bundle Analysis"
        run: npm run analyze

      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: production-build
          path: dist/

  # Job 2: Tests E2E (Post-build)
  e2e-tests:
    needs: quality-gates
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node.js 20
        uses: actions/setup-node@v4

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright
        run: npx playwright install --with-deps

      - name: Download build artifacts
        uses: actions/download-artifact@v3
        with:
          name: production-build
          path: dist/

      - name: Start preview server
        run: npm run preview &

      - name: Wait for server
        run: npx wait-on http://localhost:4173

      - name: Run E2E tests
        run: npm run test:e2e

      - name: Upload E2E results
        if: failure()
        uses: actions/upload-artifact@v3
        with:
          name: e2e-results
          path: test-results/

  # Job 3: DÃ©ploiement Production
  deploy-production:
    needs: [quality-gates, e2e-tests]
    runs-on: ubuntu-latest
    environment: production
    steps:
      - uses: actions/checkout@v4

      - name: Download build artifacts
        uses: actions/download-artifact@v3
        with:
          name: production-build
          path: dist/

      - name: Deploy to Vercel Production
        uses: amondnet/vercel-action@v25
        with:
          vercel-token: ${{ secrets.VERCEL_TOKEN }}
          vercel-org-id: ${{ secrets.ORG_ID }}
          vercel-project-id: ${{ secrets.PROJECT_ID }}
          vercel-args: "--prod"
          scope: ${{ secrets.TEAM_ID }}

      - name: Post-deploy smoke tests
        run: npm run test:smoke:production
        env:
          PRODUCTION_URL: https://doodates.app

      - name: Notify success
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.sha,
              state: 'success',
              description: 'ğŸš€ DÃ©ploiement production rÃ©ussi',
              context: 'deployment/production'
            })
```

#### C. Tests ProgrammÃ©s (Monitoring Continu)

```yaml
# .github/workflows/scheduled-monitoring.yml
name: ğŸ“Š Monitoring Continu
on:
  schedule:
    # Tests IA complets: Lundi 9h UTC
    - cron: "0 9 * * 1"
    # Tests performance: Mercredi 14h UTC
    - cron: "0 14 * * 3"
    # Tests E2E production: Vendredi 16h UTC
    - cron: "0 16 * * 5"
  workflow_dispatch:

jobs:
  ai-monitoring:
    if: github.event.schedule == '0 9 * * 1' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node.js 20
        uses: actions/setup-node@v4

      - name: Install dependencies
        run: npm ci

      - name: Run Full AI Test Suite
        run: npm run test:gemini:monitoring
        env:
          VITE_GEMINI_API_KEY: ${{ secrets.VITE_GEMINI_API_KEY }}
        timeout-minutes: 60

      - name: Generate Weekly Report
        run: npm run test:report:weekly

      - name: Create Issue if Degradation
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            const report = require('./tests/reports/weekly-report.json');
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ğŸš¨ DÃ©gradation IA dÃ©tectÃ©e - ${new Date().toLocaleDateString('fr-FR')}`,
              body: `
              ## ğŸ“Š Rapport Hebdomadaire IA
              
              **Score actuel:** ${report.currentScore}%
              **Score prÃ©cÃ©dent:** ${report.previousScore}%
              **Ã‰volution:** ${report.evolution}
              
              ### Tests Ã©chouÃ©s:
              ${report.failedTests.map(test => `- ${test.name}: ${test.error}`).join('\n')}
              
              ### Actions recommandÃ©es:
              - [ ] VÃ©rifier les changements rÃ©cents
              - [ ] Analyser les logs Gemini
              - [ ] Relancer les tests manuellement
              
              /cc @${context.actor}
              `,
              labels: ['bug', 'ai-performance', 'priority-high']
            })

  performance-monitoring:
    if: github.event.schedule == '0 14 * * 3' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node.js 20
        uses: actions/setup-node@v4

      - name: Install dependencies
        run: npm ci

      - name: Run Lighthouse CI
        run: npm run test:lighthouse

      - name: Bundle size analysis
        run: npm run analyze:bundle

      - name: Performance regression check
        run: npm run test:performance:regression

  e2e-production-monitoring:
    if: github.event.schedule == '0 16 * * 5' || github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Node.js 20
        uses: actions/setup-node@v4

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright
        run: npx playwright install --with-deps

      - name: Run E2E against production
        run: npm run test:e2e:production
        env:
          BASE_URL: https://doodates.app

      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: e2e-production-results
          path: test-results/
```

---

## ğŸ› ï¸ Scripts NPM Complets

```json
{
  "scripts": {
    // âœ… Tests Locaux
    "test:unit": "vitest run",
    "test:unit:fast": "vitest run --reporter=basic --run",
    "test:unit:watch": "vitest",
    "test:unit:coverage": "vitest run --coverage",

    "test:integration": "vitest run --config vitest.integration.config.ts",
    "test:ux-regression": "vitest run src/lib/__tests__/ux-regression.test.ts",

    // âœ… Tests IA
    "test:gemini": "jest --testPathPattern=gemini --testTimeout=30000",
    "test:gemini:quick": "jest --testPathPattern=gemini --testNamePattern='Quick' --testTimeout=15000",
    "test:gemini:production": "jest --testPathPattern=gemini --testTimeout=60000",
    "test:gemini:monitoring": "jest --testPathPattern=gemini --testTimeout=120000 --verbose",

    // âœ… Tests E2E
    "test:e2e": "playwright test",
    "test:e2e:headed": "playwright test --headed",
    "test:e2e:production": "playwright test --config=playwright.production.config.ts",
    "test:e2e:debug": "playwright test --debug",

    // âœ… Tests Performance
    "test:lighthouse": "lighthouse-ci",
    "test:performance": "npm run test:lighthouse && npm run analyze:bundle",
    "test:performance:regression": "node scripts/performance-regression.js",

    // âœ… Tests Smoke
    "test:smoke": "node scripts/smoke-tests.js",
    "test:smoke:production": "BASE_URL=https://doodates.app node scripts/smoke-tests.js",

    // âœ… Suites ComplÃ¨tes
    "test:all": "npm run test:unit && npm run test:integration && npm run test:ux-regression",
    "test:ci": "npm run test:all && npm run test:gemini:quick",
    "test:full": "npm run test:all && npm run test:gemini && npm run test:e2e",

    // âœ… Reporting
    "test:report": "node scripts/generate-test-report.js",
    "test:report:weekly": "node scripts/generate-weekly-report.js",

    // âœ… Utilitaires
    "type-check": "tsc --noEmit",
    "lint:fix": "eslint --fix src/",
    "format": "prettier --write src/",
    "analyze": "npm run analyze:bundle && npm run analyze:deps",
    "analyze:bundle": "webpack-bundle-analyzer dist/stats.json",
    "analyze:deps": "depcheck"
  }
}
```

---

## ğŸ“Š MÃ©triques et Alertes

### Seuils de QualitÃ© (Quality Gates)

```javascript
// scripts/quality-gates.js
const QUALITY_THRESHOLDS = {
  // Tests obligatoires
  unitTests: { min: 95, target: 100 },
  integrationTests: { min: 90, target: 100 },
  uxRegression: { min: 100, target: 100 }, // ZÃ©ro rÃ©gression tolÃ©rÃ©e

  // IA Performance
  aiPerformance: {
    development: { min: 70, target: 85 },
    production: { min: 95, target: 98 },
  },

  // Performance Web
  lighthouse: {
    performance: { min: 90, target: 95 },
    accessibility: { min: 95, target: 100 },
    seo: { min: 90, target: 95 },
  },

  // Code Quality
  coverage: { min: 80, target: 90 },
  bundleSize: { max: "500KB", target: "300KB" },
};
```

### Dashboard de Monitoring

```yaml
# .github/workflows/dashboard-update.yml
name: ğŸ“ˆ Dashboard Update
on:
  workflow_run:
    workflows: ["ğŸš€ Production Deploy", "ğŸ“Š Monitoring Continu"]
    types: [completed]

jobs:
  update-dashboard:
    runs-on: ubuntu-latest
    steps:
      - name: Update README badges
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = require('./tests/reports/latest-report.json');

            const badges = [
              `![Tests](https://img.shields.io/badge/Tests-${report.testsPass}%2F${report.testsTotal}-${report.testsPass === report.testsTotal ? 'green' : 'red'})`,
              `![IA Performance](https://img.shields.io/badge/IA-${report.aiScore}%25-${report.aiScore >= 95 ? 'green' : 'orange'})`,
              `![Coverage](https://img.shields.io/badge/Coverage-${report.coverage}%25-${report.coverage >= 80 ? 'green' : 'red'})`,
              `![Build](https://img.shields.io/badge/Build-${report.buildStatus}-${report.buildStatus === 'passing' ? 'green' : 'red'})`
            ];

            // Mise Ã  jour du README avec les badges
            let readme = fs.readFileSync('README.md', 'utf8');
            readme = readme.replace(/<!-- BADGES_START -->[\s\S]*<!-- BADGES_END -->/, 
              `<!-- BADGES_START -->\n${badges.join('\n')}\n<!-- BADGES_END -->`);
            fs.writeFileSync('README.md', readme);
```

---

## ğŸš€ Prochaines Actions ImmÃ©diates

### 1. Configuration des Hooks Git

```bash
# Installation husky pour les hooks
npm install -D husky
npx husky install
npx husky add .husky/pre-commit "npm run test:unit:fast && npm run test:ux-regression"
npx husky add .husky/pre-push "npm run test:ci"
```

### 2. Configuration Playwright E2E

```bash
# Installation Playwright
npm install -D @playwright/test
npx playwright install
```

### 3. Tests E2E Critiques Ã  CrÃ©er

```typescript
// tests/e2e/critical-flows.spec.ts
import { test, expect } from "@playwright/test";

test.describe("Flows Critiques DooDates", () => {
  test("Flow complet: CrÃ©ation â†’ Partage â†’ Vote â†’ RÃ©sultats", async ({ page }) => {
    // 1. CrÃ©ation de sondage
    await page.goto("/");
    await page.click('[data-testid="create-poll"]');

    // 2. Configuration dates
    await page.click('[data-date="2025-07-01"]');
    await page.click('[data-date="2025-07-02"]');

    // 3. Configuration horaires
    await page.click('[data-timeslot="09:00"]');
    await page.click('[data-timeslot="14:00"]');

    // 4. Informations sondage
    await page.fill('[data-testid="poll-title"]', "Test E2E Automatique");
    await page.fill('[data-testid="poll-emails"]', "test@example.com");

    // 5. CrÃ©ation
    await page.click('[data-testid="create-poll-button"]');

    // 6. VÃ©rification redirection
    await expect(page).toHaveURL(/\/poll\/test-e2e-automatique/);

    // 7. Test vote
    await page.click('[data-testid="vote-slot-2025-07-01-09:00"]');
    await page.click('[data-testid="submit-vote"]');

    // 8. VÃ©rification rÃ©sultats
    await expect(page.locator('[data-testid="vote-count"]')).toContainText("1");
  });

  test("IA Gemini: GÃ©nÃ©ration automatique de sondage", async ({ page }) => {
    await page.goto("/");
    await page.click('[data-testid="ai-assistant"]');
    await page.fill('[data-testid="ai-prompt"]', "Organise une rÃ©union Ã©quipe lundi matin");
    await page.click('[data-testid="ai-generate"]');

    // VÃ©rification gÃ©nÃ©ration IA
    await expect(page.locator('[data-testid="generated-title"]')).not.toBeEmpty();
    await expect(page.locator('[data-testid="generated-dates"]')).not.toBeEmpty();
  });
});
```

---

## ğŸ“Š Que Tester Maintenant ?

### ğŸ¯ **PrioritÃ© 1 : Tests E2E (Flows Critiques)**

```typescript
// tests/e2e/critical-flows.spec.ts
test("Flow complet: CrÃ©ation â†’ Partage â†’ Vote â†’ RÃ©sultats", async ({ page }) => {
  // Test du parcours utilisateur complet
});

test("IA Gemini: GÃ©nÃ©ration automatique de sondage", async ({ page }) => {
  // Test de l'intÃ©gration IA en conditions rÃ©elles
});
```

### ğŸ¯ **PrioritÃ© 2 : Tests Performance**

```bash
# Tests Lighthouse automatisÃ©s
npm run test:lighthouse

# Analyse bundle size
npm run analyze:bundle

# Tests de charge
npm run test:load
```

### ğŸ¯ **PrioritÃ© 3 : Tests d'AccessibilitÃ©**

```typescript
// tests/a11y/accessibility.spec.ts
test('Navigation au clavier', async ({ page }) => {
  // Test navigation Tab/Shift+Tab
});

test('Lecteurs d'Ã©cran', async ({ page }) => {
  // Test aria-labels et structure sÃ©mantique
});
```

---

## ğŸš€ Automatisation GitHub/Local

### âœ… **Commits Locaux**

- **Pre-commit :** Tests unitaires + UX rÃ©gression (< 30s)
- **Pre-push :** Suite complÃ¨te (< 2min)
- **Feedback immÃ©diat** : Ã‰chec = commit/push bloquÃ©

### âœ… **Pull Requests GitHub**

- **Tests parallÃ¨les** : Unit, Integration, UX, IA
- **Deploy preview** : Environnement de test automatique
- **Quality gates** : PR bloquÃ©e si tests Ã©chouent

### âœ… **Production (main branch)**

- **Quality gates stricts** : IA > 95%, tous tests passent
- **Tests E2E** : Validation complÃ¨te post-build
- **DÃ©ploiement automatique** : Seulement si 100% validÃ©

### âœ… **Monitoring Continu**

- **Tests IA hebdomadaires** : Lundi 9h UTC
- **Tests performance** : Mercredi 14h UTC
- **Tests E2E production** : Vendredi 16h UTC
- **Alertes automatiques** : Issues crÃ©Ã©es si dÃ©gradation

---

## ğŸ¯ **Prochaines Actions ImmÃ©diates**

1. **Setup Playwright E2E** (30min)
2. **Configuration hooks Git** (15min)
3. **CrÃ©ation workflows GitHub** (1h)
4. **Tests flows critiques** (2h)

**RÃ©sultat :** Tests 100% automatisÃ©s, zÃ©ro rÃ©gression possible ! ğŸš€
