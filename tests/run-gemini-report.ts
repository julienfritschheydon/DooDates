#!/usr/bin/env node

/**
 * Script simple pour gÃ©nÃ©rer le rapport aprÃ¨s les tests
 */

import { QualityTracker } from './quality-metrics.js';
import * as fs from 'fs';

async function generateSimpleReport() {
  try {
    console.log('ðŸ“Š GÃ©nÃ©ration du rapport de qualitÃ©...');
    
    const qualityTracker = new QualityTracker();
    
    // Simuler des rÃ©sultats pour la dÃ©monstration
    const mockResults = Array.from({ length: 15 }, (_, i) => ({
      testId: i + 1,
      passed: Math.random() > 0.3, // 70% de succÃ¨s simulÃ©
      score: Math.random() * 4,
      details: `Test ${i + 1} - Simulation`
    }));

    const mockTestCases = Array.from({ length: 15 }, (_, i) => ({
      id: i + 1,
      category: i < 5 ? 'RÃ©unions' : i < 10 ? 'Ã‰vÃ©nements' : 'Formations',
      weight: 4
    }));

    const metrics = qualityTracker.calculateMetrics(mockResults, mockTestCases);
    const alerts = qualityTracker.generateAlerts(metrics);
    const regression = await qualityTracker.analyzeRegression(metrics);

    const report = qualityTracker.generateQualityReport(metrics, alerts, regression || undefined);

    // CrÃ©er le dossier s'il n'existe pas
    await fs.promises.mkdir('tests/reports', { recursive: true });
    
    // Sauvegarder le rapport
    await fs.promises.writeFile('tests/reports/quality-report.md', report, 'utf8');

    console.log('âœ… Rapport gÃ©nÃ©rÃ© : tests/reports/quality-report.md');
    console.log(`ðŸ“Š Score : ${metrics.totalScore}/${metrics.maxScore} (${metrics.percentage}%)`);

  } catch (error) {
    console.error('âŒ Erreur lors de la gÃ©nÃ©ration:', error);
    process.exit(1);
  }
}

if (require.main === module) {
  generateSimpleReport();
} 