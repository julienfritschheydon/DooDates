#!/usr/bin/env node
/**
 * Script pour monitorer les √©checs de workflows GitHub Actions
 * G√©n√®re un rapport consultable par l'IA dans le d√©p√¥t
 */

import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import dotenv from 'dotenv';

// Charger les variables d'environnement depuis .env.local si disponible
const envLocalPath = path.join(process.cwd(), '.env.local');
if (fs.existsSync(envLocalPath)) {
  dotenv.config({ path: envLocalPath });
}

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Configuration
const REPORT_DIR = path.join(process.cwd(), 'Docs', 'monitoring');
const REPORT_FILE = path.join(REPORT_DIR, 'workflow-failures-report.md');
const ARTIFACTS_DIR = path.join(process.cwd(), 'temp-artifacts');
const GITHUB_API_BASE = process.env.GITHUB_API_URL || 'https://api.github.com';
const REPO = process.env.GITHUB_REPOSITORY || 'owner/repo';
const GITHUB_TOKEN = process.env.GITHUB_TOKEN;

// Workflows √† monitorer
const WORKFLOWS_TO_MONITOR = [
  '1Ô∏è‚É£ PR Complete Validation',
  '2Ô∏è‚É£ Develop ‚Üí Main (Auto-merge)',
  '3Ô∏è‚É£ Main Post-Merge E2E',
  '4Ô∏è‚É£ Main Deploy Pages',
  '6Ô∏è‚É£ Nightly Full Regression',
  '7Ô∏è‚É£ Monthly Gemini',
];

/**
 * R√©cup√®re les workflows du d√©p√¥t
 */
async function getWorkflows() {
  if (!GITHUB_TOKEN) {
    console.warn('‚ö†Ô∏è GITHUB_TOKEN non d√©fini, utilisation de donn√©es mock√©es');
    return getMockWorkflows();
  }

  try {
    const response = await fetch(`${GITHUB_API_BASE}/repos/${REPO}/actions/workflows`, {
      headers: {
        'Authorization': `Bearer ${GITHUB_TOKEN}`,
        'Accept': 'application/vnd.github.v3+json',
      },
    });

    if (!response.ok) {
      throw new Error(`API Error: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    return data.workflows || [];
  } catch (error) {
    console.error('‚ùå Erreur lors de la r√©cup√©ration des workflows:', error.message);
    return getMockWorkflows();
  }
}

/**
 * R√©cup√®re les runs r√©cents d'un workflow
 */
async function getWorkflowRuns(workflowId, limit = 10) {
  if (!GITHUB_TOKEN) {
    return getMockRuns();
  }

  try {
    const response = await fetch(
      `${GITHUB_API_BASE}/repos/${REPO}/actions/workflows/${workflowId}/runs?per_page=${limit}`,
      {
        headers: {
          'Authorization': `Bearer ${GITHUB_TOKEN}`,
          'Accept': 'application/vnd.github.v3+json',
        },
      }
    );

    if (!response.ok) {
      throw new Error(`API Error: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    return data.workflow_runs || [];
  } catch (error) {
    console.error(`‚ùå Erreur lors de la r√©cup√©ration des runs pour workflow ${workflowId}:`, error.message);
    return getMockRuns();
  }
}

/**
 * R√©cup√®re les jobs d'un run
 */
async function getRunJobs(runId) {
  if (!GITHUB_TOKEN) {
    return getMockJobs();
  }

  try {
    const response = await fetch(
      `${GITHUB_API_BASE}/repos/${REPO}/actions/runs/${runId}/jobs?per_page=100`,
      {
        headers: {
          'Authorization': `Bearer ${GITHUB_TOKEN}`,
          'Accept': 'application/vnd.github.v3+json',
        },
      }
    );

    if (!response.ok) {
      throw new Error(`API Error: ${response.status} ${response.statusText}`);
    }

    const data = await response.json();
    return data.jobs || [];
  } catch (error) {
    console.error(`‚ùå Erreur lors de la r√©cup√©ration des jobs pour run ${runId}:`, error.message);
    return getMockJobs();
  }
}

/**
 * R√©cup√®re les logs d'un job
 */
async function getJobLogs(jobId) {
  if (!GITHUB_TOKEN) {
    return null;
  }

  try {
    const response = await fetch(
      `${GITHUB_API_BASE}/repos/${REPO}/actions/jobs/${jobId}/logs`,
      {
        headers: {
          'Authorization': `Bearer ${GITHUB_TOKEN}`,
          'Accept': 'application/vnd.github.v3+json',
        },
      }
    );

    if (!response.ok) {
      throw new Error(`API Error: ${response.status} ${response.statusText}`);
    }

    return await response.text();
  } catch (error) {
    console.error(`‚ùå Erreur lors de la r√©cup√©ration des logs pour job ${jobId}:`, error.message);
    return null;
  }
}

/**
 * Analyse les artefacts de test t√©l√©charg√©s pour extraire les √©checs d√©taill√©s
 */
function analyzeTestArtifacts(runId) {
  const runDir = path.join(ARTIFACTS_DIR, runId.toString());
  if (!fs.existsSync(runDir)) {
    return null;
  }

  const failures = [];
  
  // Chercher les fichiers test-results.json dans les artefacts
  const findJsonFiles = (dir) => {
    const files = [];
    if (!fs.existsSync(dir)) return files;
    
    const items = fs.readdirSync(dir, { withFileTypes: true });
    for (const item of items) {
      const fullPath = path.join(dir, item.name);
      if (item.isDirectory()) {
        files.push(...findJsonFiles(fullPath));
      } else if (item.name === 'test-results.json') {
        files.push(fullPath);
      }
    }
    return files;
  };

  const jsonFiles = findJsonFiles(runDir);
  
  for (const jsonFile of jsonFiles) {
    try {
      const content = JSON.parse(fs.readFileSync(jsonFile, 'utf-8'));
      
      // Analyser les r√©sultats Playwright
      if (content.suites) {
        for (const suite of content.suites) {
          for (const spec of suite.specs || []) {
            for (const test of spec.tests || []) {
              for (const result of test.results || []) {
                if (result.status === 'failed' || result.status === 'timedOut') {
                  failures.push({
                    file: spec.file,
                    title: spec.title,
                    error: result.error?.message || 'Unknown error',
                    browser: suite.title,
                  });
                }
              }
            }
          }
        }
      }
    } catch (err) {
      console.error(`‚ö†Ô∏è Erreur lors de l'analyse de ${jsonFile}:`, err.message);
    }
  }

  return failures.length > 0 ? failures : null;
}

/**
 * Extrait les erreurs principales des logs avec num√©ros de lignes et d√©tails
 */
function extractErrorsFromLogs(logs) {
  if (!logs) return [];
  
  const errors = [];
  const lines = logs.split('\n');
  
  // Patterns pour d√©tecter les erreurs de tests Vitest
  const vitestFailurePattern = /FAIL\s+(.+\.test\.(?:ts|tsx|js|jsx))\s+\((\d+)\s+test.*?\)/i;
  const vitestTestPattern = /√ó\s+(.+?)\s+\((\d+)\s+ms\)/;
  const vitestAssertPattern = /AssertionError|Expected.*but got|Expected.*received/i;
  const vitestSummaryPattern = /Test Files\s+(\d+)\s+failed/i;
  const vitestTestCountPattern = /Tests\s+(\d+)\s+failed/i;
  
  // Patterns pour d√©tecter les erreurs Playwright
  const playwrightErrorPattern = /Error:\s+.*expect\(.*\)\.(toContainText|toBeVisible|toBeEnabled|toHaveText)/i;
  const playwrightTimeoutPattern = /Timeout.*ms|element\(s\) not found/i;
  const playwrightLocatorPattern = /Locator:\s+(.+)/i;
  const playwrightExpectedPattern = /Expected.*:\s*(.+)/i;
  
  // Patterns g√©n√©raux
  const errorPattern = /(Error|AssertionError|TypeError|ReferenceError|SyntaxError|Test failed)/i;
  const fileLinePattern = /at\s+(.+?):(\d+):(\d+)/;
  const fileLinePattern2 = /(.+\.(?:ts|tsx|js|jsx|spec\.ts)):(\d+):(\d+)/;
  
  let currentError = null;
  let errorContext = [];
  let inErrorBlock = false;
  
  for (let i = 0; i < lines.length; i++) {
    const line = lines[i];
    const lineNum = i + 1;
    
    // D√©tecter un √©chec de test Vitest
    const vitestMatch = line.match(vitestFailurePattern);
    if (vitestMatch) {
      if (currentError) {
        errors.push({
          type: 'test_failure',
          file: currentError.file,
          testName: currentError.testName,
          message: currentError.message,
          context: errorContext.join('\n'),
          line: currentError.line,
        });
      }
      currentError = {
        file: vitestMatch[1],
        testName: null,
        message: null,
        line: lineNum,
      };
      errorContext = [line];
      inErrorBlock = true;
      continue;
    }
    
    // D√©tecter une erreur Playwright
    if (playwrightErrorPattern.test(line) || playwrightTimeoutPattern.test(line)) {
      if (!currentError) {
        currentError = {
          file: null,
          testName: null,
          message: line.trim(),
          line: lineNum,
        };
        inErrorBlock = true;
      }
      errorContext.push(line);
      
      // Chercher le locator et l'expected
      const locatorMatch = line.match(playwrightLocatorPattern);
      if (locatorMatch && currentError) {
        currentError.message = `${currentError.message}\nLocator: ${locatorMatch[1]}`;
      }
      const expectedMatch = line.match(playwrightExpectedPattern);
      if (expectedMatch && currentError) {
        currentError.message = `${currentError.message}\nExpected: ${expectedMatch[1]}`;
      }
      continue;
    }
    
    // D√©tecter le nom du test qui √©choue (Vitest)
    const vitestTestMatch = line.match(vitestTestPattern);
    if (vitestTestMatch && currentError) {
      currentError.testName = vitestTestMatch[1].trim();
      errorContext.push(line);
      continue;
    }
    
    // D√©tecter un fichier de test dans la ligne (pour Playwright)
    const fileMatch2 = line.match(fileLinePattern2);
    if (fileMatch2 && currentError && !currentError.file) {
      currentError.file = fileMatch2[1];
      currentError.line = fileMatch2[2];
      errorContext.push(line);
      continue;
    }
    
    // D√©tecter une erreur (Vitest assertion)
    if (vitestAssertPattern.test(line) || (errorPattern.test(line) && !playwrightErrorPattern.test(line))) {
      if (!currentError) {
        currentError = {
          file: null,
          testName: null,
          message: null,
          line: lineNum,
        };
        inErrorBlock = true;
      }
      if (!currentError.message) {
        currentError.message = line.trim();
      }
      errorContext.push(line);
      continue;
    }
    
    // D√©tecter un fichier et num√©ro de ligne dans la stack trace
    const fileMatch = line.match(fileLinePattern);
    if (fileMatch && currentError && !currentError.file) {
      currentError.file = fileMatch[1];
      currentError.line = fileMatch[2];
      errorContext.push(line);
      continue;
    }
    
    // Continuer √† collecter le contexte de l'erreur
    if (inErrorBlock && currentError) {
      // Collecter jusqu'√† 15 lignes de contexte
      if (errorContext.length < 15) {
        if (line.trim().startsWith('at ') || 
            line.trim().startsWith('  ') || 
            line.trim().startsWith('‚ùå') ||
            line.trim().startsWith('√ó') ||
            line.trim() === '' ||
            /^\s+\^/.test(line) ||
            /Expected|Received|Assertion|Error/.test(line)) {
          errorContext.push(line);
        } else if (errorContext.length > 3) {
          // Fin du bloc d'erreur
          errors.push({
            type: currentError.testName ? 'test_failure' : 'error',
            file: currentError.file || 'unknown',
            testName: currentError.testName,
            message: currentError.message || errorContext[0] || 'Unknown error',
            context: errorContext.join('\n'),
            line: currentError.line,
          });
          currentError = null;
          errorContext = [];
          inErrorBlock = false;
        }
      } else {
        // Trop de lignes, sauvegarder et continuer
        errors.push({
          type: currentError.testName ? 'test_failure' : 'error',
          file: currentError.file || 'unknown',
          testName: currentError.testName,
          message: currentError.message || errorContext[0] || 'Unknown error',
          context: errorContext.join('\n'),
          line: currentError.line,
        });
        currentError = null;
        errorContext = [];
        inErrorBlock = false;
      }
    }
  }
  
  // Sauvegarder la derni√®re erreur
  if (currentError && errorContext.length > 0) {
    errors.push({
      type: currentError.testName ? 'test_failure' : 'error',
      file: currentError.file || 'unknown',
      testName: currentError.testName,
      message: currentError.message || errorContext[0] || 'Unknown error',
      context: errorContext.join('\n'),
      line: currentError.line,
    });
  }
  
  // Filtrer les erreurs : exclure les logs normaux (Storage error de fallback Supabase)
  const filteredErrors = errors.filter(err => {
    // Exclure les erreurs qui sont juste des logs de fallback Supabase
    if (err.message && err.message.includes('Erreur lors du chargement depuis Supabase, utilisation de localStorage')) {
      // Garder seulement si c'est un vrai √©chec de test (avec testName)
      return err.testName !== null;
    }
    // Garder toutes les autres erreurs
    return true;
  });
  
  // Formater les erreurs pour l'affichage
  return filteredErrors.slice(0, 10).map(err => {
    let formatted = '';
    if (err.testName) {
      formatted += `Test: ${err.testName}\n`;
    }
    if (err.file && err.file !== 'unknown') {
      // Nettoyer le chemin du fichier (enlever les codes ANSI et chemins absolus)
      let cleanFile = err.file.replace(/\x1b\[[0-9;]*m/g, ''); // Enlever codes ANSI
      cleanFile = cleanFile.replace(/.*\/(src|tests)\//, '$1/'); // Simplifier le chemin
      formatted += `File: ${cleanFile}`;
      if (err.line) {
        formatted += `:${err.line}`;
      }
      formatted += '\n';
    }
    // Nettoyer le message (enlever timestamps et codes ANSI)
    let cleanMessage = err.message.replace(/\d{4}-\d{2}-\d{2}T[\d:\.]+Z\s*/g, ''); // Timestamps
    cleanMessage = cleanMessage.replace(/\x1b\[[0-9;]*m/g, ''); // Codes ANSI
    cleanMessage = cleanMessage.replace(/\[22m|\[39m|\[90m|\[2m/g, ''); // Codes ANSI sp√©cifiques
    formatted += `Error: ${cleanMessage.trim()}\n`;
    if (err.context) {
      // Nettoyer le contexte aussi
      let cleanContext = err.context.replace(/\d{4}-\d{2}-\d{2}T[\d:\.]+Z\s*/g, '');
      cleanContext = cleanContext.replace(/\x1b\[[0-9;]*m/g, '');
      cleanContext = cleanContext.replace(/\[22m|\[39m|\[90m|\[2m/g, '');
      formatted += `\n${cleanContext.substring(0, 800)}`;
      if (cleanContext.length > 800) {
        formatted += '\n... (truncated)';
      }
    }
    return formatted;
  });
}

/**
 * G√©n√®re le rapport markdown
 */
async function generateReport() {
  console.log('üìä G√©n√©ration du rapport de monitoring des workflows...\n');

  const workflows = await getWorkflows();
  const reportSections = [];
  
  // En-t√™te du rapport
  const now = new Date();
  reportSections.push(`# üìä Rapport de Monitoring des Workflows GitHub Actions\n\n`);
  reportSections.push(`**Derni√®re mise √† jour:** ${now.toLocaleString('fr-FR', { timeZone: 'Europe/Paris' })}\n\n`);
  reportSections.push(`> Ce rapport est g√©n√©r√© automatiquement pour suivre les √©checs de workflows.\n`);
  reportSections.push(`> Il peut √™tre consult√© par l'IA pour comprendre l'√©tat de sant√© du CI/CD.\n\n`);
  reportSections.push(`---\n\n`);

  // Analyser chaque workflow
  for (const workflowName of WORKFLOWS_TO_MONITOR) {
    const workflow = workflows.find(w => w.name === workflowName);
    
    if (!workflow) {
      console.log(`‚ö†Ô∏è Workflow "${workflowName}" non trouv√©`);
      continue;
    }

    console.log(`üìã Analyse de "${workflowName}"...`);
    const runs = await getWorkflowRuns(workflow.id, 20);
    
    // Filtrer les √©checs r√©cents (derni√®res 24h)
    const oneDayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000);
    const recentFailures = runs.filter(run => {
      const runDate = new Date(run.created_at);
      return runDate >= oneDayAgo && run.conclusion === 'failure';
    });

    // Filtrer les √©checs des 7 derniers jours
    const sevenDaysAgo = new Date(Date.now() - 7 * 24 * 60 * 60 * 1000);
    const weekFailures = runs.filter(run => {
      const runDate = new Date(run.created_at);
      return runDate >= sevenDaysAgo && run.conclusion === 'failure';
    });

    // Dernier run
    const lastRun = runs[0];
    const lastRunDate = lastRun ? new Date(lastRun.created_at) : null;
    const lastRunStatus = lastRun ? lastRun.conclusion : 'unknown';

    // Section du workflow
    reportSections.push(`## ${workflowName}\n\n`);
    
    // Statut global
    const statusEmoji = lastRunStatus === 'success' ? '‚úÖ' : 
                        lastRunStatus === 'failure' ? '‚ùå' : 
                        lastRunStatus === 'cancelled' ? '‚è∏Ô∏è' : '‚è≥';
    
    reportSections.push(`**Statut:** ${statusEmoji} ${lastRunStatus || 'unknown'}\n\n`);
    
    if (lastRunDate) {
      reportSections.push(`**Dernier run:** ${lastRunDate.toLocaleString('fr-FR', { timeZone: 'Europe/Paris' })}\n\n`);
    }

    // Statistiques
    reportSections.push(`**Statistiques:**\n`);
    reportSections.push(`- ‚ùå √âchecs (24h): **${recentFailures.length}**\n`);
    reportSections.push(`- ‚ùå √âchecs (7 jours): **${weekFailures.length}**\n`);
    reportSections.push(`- üìä Total runs analys√©s: **${runs.length}**\n\n`);

    // D√©tails des √©checs r√©cents
    if (recentFailures.length > 0) {
      reportSections.push(`### üî¥ √âchecs r√©cents (24h)\n\n`);
      
      for (const failure of recentFailures.slice(0, 5)) {
        const failureDate = new Date(failure.created_at);
        const jobs = await getRunJobs(failure.id);
        const failedJobs = jobs.filter(j => j.conclusion === 'failure');
        
        reportSections.push(`#### Run #${failure.run_number} - ${failureDate.toLocaleString('fr-FR', { timeZone: 'Europe/Paris' })}\n\n`);
        reportSections.push(`- **Commit:** \`${failure.head_sha.substring(0, 7)}\`\n`);
        reportSections.push(`- **Auteur:** ${failure.actor?.login || 'unknown'}\n`);
        reportSections.push(`- **Branche:** \`${failure.head_branch}\`\n`);
        reportSections.push(`- **Lien:** [Voir les d√©tails](${failure.html_url})\n`);
        
        if (failedJobs.length > 0) {
          reportSections.push(`- **Jobs en √©chec:**\n`);
          for (const job of failedJobs) {
            reportSections.push(`  - ‚ùå \`${job.name}\` (${job.conclusion})\n`);
            // Afficher les steps qui ont √©chou√©
            if (job.steps && job.steps.length > 0) {
              const failedSteps = job.steps.filter(s => s.conclusion === 'failure');
              if (failedSteps.length > 0) {
                reportSections.push(`    - Steps en √©chec: ${failedSteps.map(s => `\`${s.name}\``).join(', ')}\n`);
              }
            }
            
            // Pour le dernier run seulement, analyser les artefacts ou les logs
            if (failure.id === recentFailures[0].id) {
              // D'abord essayer d'analyser les artefacts t√©l√©charg√©s
              const artifactFailures = analyzeTestArtifacts(failure.id);
              if (artifactFailures && artifactFailures.length > 0) {
                reportSections.push(`    - **Tests en √©chec (${artifactFailures.length}):**\n`);
                for (const testFailure of artifactFailures.slice(0, 10)) {
                  reportSections.push(`      - ‚ùå **[${testFailure.browser}]** \`${testFailure.file}\`\n`);
                  reportSections.push(`        - Test: ${testFailure.title}\n`);
                  reportSections.push(`        - Erreur: \`${testFailure.error.substring(0, 200)}${testFailure.error.length > 200 ? '...' : ''}\`\n`);
                }
                if (artifactFailures.length > 10) {
                  reportSections.push(`      *... et ${artifactFailures.length - 10} autre(s) test(s) en √©chec*\n`);
                }
              } else if (GITHUB_TOKEN) {
                // Fallback sur les logs si pas d'artefacts
                try {
                  console.log(`  üì• R√©cup√©ration des logs pour job ${job.id}...`);
                  const logs = await getJobLogs(job.id);
                  if (logs) {
                    const errors = extractErrorsFromLogs(logs);
                    if (errors.length > 0) {
                      reportSections.push(`    - **Erreurs d√©tect√©es (${errors.length}):**\n`);
                      for (const error of errors.slice(0, 5)) {
                        reportSections.push(`      \`\`\`\n${error}\n\`\`\`\n`);
                      }
                      if (errors.length > 5) {
                        reportSections.push(`      *... et ${errors.length - 5} autre(s) erreur(s)*\n`);
                      }
                    } else {
                      reportSections.push(`    - ‚ö†Ô∏è Aucune erreur structur√©e d√©tect√©e\n`);
                    }
                  }
                } catch (err) {
                  reportSections.push(`    - ‚ö†Ô∏è Impossible de r√©cup√©rer les d√©tails: ${err.message}\n`);
                }
              }
            }
          }
        }
        
        reportSections.push(`\n`);
      }
    } else if (weekFailures.length > 0) {
      reportSections.push(`### ‚ö†Ô∏è √âchecs r√©cents (7 jours)\n\n`);
      reportSections.push(`Aucun √©chec dans les 24 derni√®res heures, mais **${weekFailures.length}** √©chec(s) cette semaine.\n\n`);
    } else {
      reportSections.push(`### ‚úÖ Aucun √©chec r√©cent\n\n`);
      reportSections.push(`Aucun √©chec d√©tect√© dans les 7 derniers jours.\n\n`);
    }

    reportSections.push(`---\n\n`);
  }

  // R√©sum√© global
  reportSections.push(`## üìà R√©sum√© Global\n\n`);
  
  const allRuns = [];
  for (const workflow of workflows.filter(w => WORKFLOWS_TO_MONITOR.includes(w.name))) {
    const runs = await getWorkflowRuns(workflow.id, 10);
    allRuns.push(...runs);
  }

  const oneDayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000);
  const totalFailures24h = allRuns.filter(run => {
    const runDate = new Date(run.created_at);
    return runDate >= oneDayAgo && run.conclusion === 'failure';
  }).length;

  const totalFailures7d = allRuns.filter(run => {
    const runDate = new Date(run.created_at);
    const sevenDaysAgo = new Date(Date.now() - 7 * 24 * 60 * 60 * 1000);
    return runDate >= sevenDaysAgo && run.conclusion === 'failure';
  }).length;

  reportSections.push(`- ‚ùå **Total √©checs (24h):** ${totalFailures24h}\n`);
  reportSections.push(`- ‚ùå **Total √©checs (7 jours):** ${totalFailures7d}\n`);
  reportSections.push(`- üìä **Workflows monitor√©s:** ${WORKFLOWS_TO_MONITOR.length}\n\n`);

  // Recommandations
  if (totalFailures24h > 0) {
    reportSections.push(`### ‚ö†Ô∏è Recommandations\n\n`);
    reportSections.push(`Des √©checs ont √©t√© d√©tect√©s dans les 24 derni√®res heures. `);
    reportSections.push(`Consultez les sections ci-dessus pour plus de d√©tails.\n\n`);
  } else {
    reportSections.push(`### ‚úÖ √âtat de sant√©\n\n`);
    reportSections.push(`Aucun √©chec d√©tect√© dans les 24 derni√®res heures. Le syst√®me CI/CD est en bonne sant√©.\n\n`);
  }

  // √âcrire le rapport
  const reportContent = reportSections.join('');
  
  // Cr√©er le dossier si n√©cessaire
  if (!fs.existsSync(REPORT_DIR)) {
    fs.mkdirSync(REPORT_DIR, { recursive: true });
  }

  fs.writeFileSync(REPORT_FILE, reportContent, 'utf-8');
  console.log(`\n‚úÖ Rapport g√©n√©r√©: ${REPORT_FILE}`);
  console.log(`üìä ${totalFailures24h} √©chec(s) d√©tect√©(s) dans les 24h`);

  // G√©n√©rer un fichier JSON de statut rapide pour consultation facile
  const statusFile = path.join(REPORT_DIR, 'workflow-status.json');
  const statusData = {
    lastUpdate: now.toISOString(),
    totalFailures24h,
    totalFailures7d,
    workflowsMonitored: WORKFLOWS_TO_MONITOR.length,
    hasFailures: totalFailures24h > 0,
    reportPath: 'Docs/monitoring/workflow-failures-report.md',
  };
  fs.writeFileSync(statusFile, JSON.stringify(statusData, null, 2), 'utf-8');
  console.log(`üìä Statut rapide g√©n√©r√©: ${statusFile}`);

  // Cr√©er/mettre √† jour une issue GitHub si √©checs critiques
  if (totalFailures24h > 0 && GITHUB_TOKEN) {
    await createOrUpdateAlertIssue(totalFailures24h, totalFailures7d, reportContent);
  } else if (totalFailures24h === 0 && GITHUB_TOKEN) {
    // Fermer les issues d'alerte si tout est OK
    await closeAlertIssuesIfResolved();
  }
}

/**
 * Cr√©e ou met √† jour une issue d'alerte pour les √©checs critiques
 */
async function createOrUpdateAlertIssue(failures24h, failures7d, reportContent) {
  if (!GITHUB_TOKEN) {
    console.log('‚ö†Ô∏è GITHUB_TOKEN non disponible, skip cr√©ation issue');
    return;
  }

  try {
    const today = new Date().toISOString().split('T')[0];
    const issueTitle = `üö® CI/CD Health Alert - ${failures24h} √©chec(s) dans les 24h`;

    // Chercher une issue existante ouverte avec le label 'ci-health'
    const response = await fetch(
      `${GITHUB_API_BASE}/repos/${REPO}/issues?state=open&labels=ci-health,automated&per_page=10`,
      {
        headers: {
          'Authorization': `Bearer ${GITHUB_TOKEN}`,
          'Accept': 'application/vnd.github.v3+json',
        },
      }
    );
    
    let issues = [];
    if (response.ok) {
      issues = await response.json();
    }

    const existingIssue = issues.find(issue => 
      issue.title.includes('CI/CD Health Alert') && 
      issue.state === 'open'
    );

    const issueBody = `## üö® Alerte Sant√© CI/CD

**Date:** ${new Date().toLocaleString('fr-FR', { timeZone: 'Europe/Paris' })}

### üìä R√©sum√©
- ‚ùå **√âchecs (24h):** ${failures24h}
- ‚ùå **√âchecs (7 jours):** ${failures7d}
- üìä **Workflows monitor√©s:** ${WORKFLOWS_TO_MONITOR.length}

### üìã Rapport Complet
Consultez le [rapport d√©taill√©](https://github.com/${REPO}/blob/main/Docs/monitoring/workflow-failures-report.md) pour plus d'informations.

### ü§ñ Pour l'IA
Lorsque cette issue est ouverte, l'IA doit automatiquement consulter le fichier \`Docs/monitoring/workflow-failures-report.md\` pour analyser les √©checs et proposer des solutions.

---

*Cette issue est g√©n√©r√©e automatiquement par le workflow de monitoring. Elle sera ferm√©e automatiquement quand il n'y aura plus d'√©checs dans les 24h.*`;

    if (existingIssue) {
      // Mettre √† jour l'issue existante
      await fetch(
        `${GITHUB_API_BASE}/repos/${REPO}/issues/${existingIssue.number}`,
        {
          method: 'PATCH',
          headers: {
            'Authorization': `Bearer ${GITHUB_TOKEN}`,
            'Accept': 'application/vnd.github.v3+json',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            title: issueTitle,
            body: issueBody,
          }),
        }
      );

      // Ajouter un commentaire avec le nouveau statut
      await fetch(
        `${GITHUB_API_BASE}/repos/${REPO}/issues/${existingIssue.number}/comments`,
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${GITHUB_TOKEN}`,
            'Accept': 'application/vnd.github.v3+json',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            body: `üîÑ **Mise √† jour** - ${new Date().toLocaleString('fr-FR', { timeZone: 'Europe/Paris' })}\n\n${failures24h} √©chec(s) d√©tect√©(s) dans les 24 derni√®res heures.`,
          }),
        }
      );

      console.log(`‚úÖ Issue #${existingIssue.number} mise √† jour`);
    } else {
      // Cr√©er une nouvelle issue
      const response = await fetch(
        `${GITHUB_API_BASE}/repos/${REPO}/issues`,
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${GITHUB_TOKEN}`,
            'Accept': 'application/vnd.github.v3+json',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            title: issueTitle,
            body: issueBody,
            labels: ['ci-health', 'automated', 'urgent'],
          }),
        }
      );

      if (response.ok) {
        const issue = await response.json();
        console.log(`‚úÖ Issue #${issue.number} cr√©√©e pour alerter sur les √©checs`);
      } else {
        const error = await response.text();
        console.error(`‚ùå Erreur lors de la cr√©ation de l'issue: ${response.status} ${error}`);
      }
    }
  } catch (error) {
    console.error('‚ùå Erreur lors de la cr√©ation/mise √† jour de l\'issue:', error.message);
  }
}

/**
 * Ferme les issues d'alerte si tout est r√©solu
 */
async function closeAlertIssuesIfResolved() {
  if (!GITHUB_TOKEN) {
    return;
  }

  try {
    const response = await fetch(
      `${GITHUB_API_BASE}/repos/${REPO}/issues?state=open&labels=ci-health,automated&per_page=10`,
      {
        headers: {
          'Authorization': `Bearer ${GITHUB_TOKEN}`,
          'Accept': 'application/vnd.github.v3+json',
        },
      }
    );
    
    let issues = [];
    if (response.ok) {
      issues = await response.json();
    }

    const alertIssues = issues.filter(issue => 
      issue.title.includes('CI/CD Health Alert')
    );

    for (const issue of alertIssues) {
      await fetch(
        `${GITHUB_API_BASE}/repos/${REPO}/issues/${issue.number}`,
        {
          method: 'PATCH',
          headers: {
            'Authorization': `Bearer ${GITHUB_TOKEN}`,
            'Accept': 'application/vnd.github.v3+json',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            state: 'closed',
            state_reason: 'completed',
          }),
        }
      );

      // Ajouter un commentaire de r√©solution
      await fetch(
        `${GITHUB_API_BASE}/repos/${REPO}/issues/${issue.number}/comments`,
        {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${GITHUB_TOKEN}`,
            'Accept': 'application/vnd.github.v3+json',
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            body: `‚úÖ **R√©solu** - ${new Date().toLocaleString('fr-FR', { timeZone: 'Europe/Paris' })}\n\nAucun √©chec d√©tect√© dans les 24 derni√®res heures. Le syst√®me CI/CD est de nouveau en bonne sant√©.`,
          }),
        }
      );

      console.log(`‚úÖ Issue #${issue.number} ferm√©e (probl√®mes r√©solus)`);
    }
  } catch (error) {
    console.error('‚ùå Erreur lors de la fermeture des issues:', error.message);
  }
}

// Fonctions mock pour les tests sans token
function getMockWorkflows() {
  return WORKFLOWS_TO_MONITOR.map((name, index) => ({
    id: index + 1,
    name,
    path: `.github/workflows/${index + 1}-workflow.yml`,
  }));
}

function getMockRuns() {
  return [];
}

function getMockJobs() {
  return [];
}

// Ex√©cution
generateReport().catch(error => {
  console.error('‚ùå Erreur lors de la g√©n√©ration du rapport:', error);
  process.exit(1);
});

