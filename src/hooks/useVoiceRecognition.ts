/**
 * Hook pour la reconnaissance vocale avec Web Speech API
 * Permet de transcrire la voix en texte pour le chat
 */

import { useState, useEffect, useCallback, useRef } from "react";

// Types pour Web Speech API (non inclus dans TypeScript par dÃ©faut)
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
}

interface SpeechRecognitionConstructor {
  new (): SpeechRecognition;
}

declare global {
  interface Window {
    SpeechRecognition: SpeechRecognitionConstructor;
    webkitSpeechRecognition: SpeechRecognitionConstructor;
  }
}

export interface VoiceRecognitionState {
  /** Texte transcrit en cours (interim) */
  interimTranscript: string;
  /** Texte transcrit final */
  finalTranscript: string;
  /** Est en train d'Ã©couter */
  isListening: boolean;
  /** Erreur Ã©ventuelle */
  error: string | null;
  /** API supportÃ©e par le navigateur */
  isSupported: boolean;
}

export interface VoiceRecognitionActions {
  /** DÃ©marrer l'Ã©coute */
  startListening: () => void;
  /** ArrÃªter l'Ã©coute */
  stopListening: () => void;
  /** RÃ©initialiser la transcription */
  resetTranscript: () => void;
}

export interface UseVoiceRecognitionOptions {
  /** Langue de reconnaissance (dÃ©faut: 'fr-FR') */
  lang?: string;
  /** RÃ©sultats intermÃ©diaires (dÃ©faut: true) */
  interimResults?: boolean;
  /** Ã‰coute continue (dÃ©faut: false) */
  continuous?: boolean;
  /** Callback quand transcription finale */
  onTranscriptChange?: (transcript: string) => void;
  /** Callback quand erreur */
  onError?: (error: string) => void;
}

/**
 * Hook pour utiliser la reconnaissance vocale
 */
export function useVoiceRecognition(
  options: UseVoiceRecognitionOptions = {},
): VoiceRecognitionState & VoiceRecognitionActions {
  const {
    lang = "fr-FR",
    interimResults = true,
    continuous = false,
    onTranscriptChange,
    onError,
  } = options;

  const [interimTranscript, setInterimTranscript] = useState("");
  const [finalTranscript, setFinalTranscript] = useState("");
  const [isListening, setIsListening] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [isSupported, setIsSupported] = useState(false);

  const recognitionRef = useRef<SpeechRecognition | null>(null);

  // VÃ©rifier support navigateur
  useEffect(() => {
    const SpeechRecognitionAPI = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (SpeechRecognitionAPI) {
      setIsSupported(true);
      recognitionRef.current = new SpeechRecognitionAPI();
    } else {
      setIsSupported(false);
      console.warn("Web Speech API non supportÃ©e par ce navigateur");
    }
  }, []);

  // Configurer la reconnaissance vocale
  useEffect(() => {
    const recognition = recognitionRef.current;
    if (!recognition) return;

    recognition.continuous = continuous;
    recognition.interimResults = interimResults;
    recognition.lang = lang;

    recognition.onstart = () => {
      setIsListening(true);
      setError(null);
      console.log("ðŸŽ¤ Reconnaissance vocale dÃ©marrÃ©e");
    };

    recognition.onend = () => {
      console.log("ðŸŽ¤ Reconnaissance vocale arrÃªtÃ©e");

      // ðŸ”§ FIX: RedÃ©marrer automatiquement en mode continu
      // Web Speech API s'arrÃªte aprÃ¨s ~5-15 secondes, on le relance
      if (continuous && isListening) {
        console.log("ðŸ”„ RedÃ©marrage automatique dans 300ms...");
        setTimeout(() => {
          try {
            recognition.start();
          } catch (error) {
            console.warn("âš ï¸ Impossible de redÃ©marrer:", error);
          }
        }, 300); // DÃ©lai pour laisser le temps Ã  la transcription finale
      } else {
        setIsListening(false);
      }
    };

    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      console.error("âŒ Erreur reconnaissance vocale:", event.error);

      // Ignorer l'erreur "no-speech" (silence normal, pas une vraie erreur)
      if (event.error === "no-speech") {
        console.log("â¸ï¸ Silence dÃ©tectÃ©, arrÃªt normal");
        return;
      }

      let errorMessage = "Erreur de reconnaissance vocale";

      switch (event.error) {
        case "no-speech":
          errorMessage = "Aucune parole dÃ©tectÃ©e";
          break;
        case "audio-capture":
          errorMessage = "Microphone non accessible";
          break;
        case "not-allowed":
          errorMessage = "Permission microphone refusÃ©e";
          break;
        case "network":
          errorMessage = "Erreur rÃ©seau";
          break;
        case "aborted":
          errorMessage = "Reconnaissance interrompue";
          break;
        default:
          errorMessage = `Erreur: ${event.error}`;
      }

      setError(errorMessage);
      setIsListening(false);

      if (onError) {
        onError(errorMessage);
      }
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      let interim = "";
      let final = "";

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;

        if (event.results[i].isFinal) {
          final += transcript + " ";
          console.log("ðŸ“ Transcription finale:", transcript);
        } else {
          interim += transcript;
          console.log("ðŸ“ Transcription intermÃ©diaire:", transcript);
        }
      }

      setInterimTranscript(interim);

      if (final) {
        setFinalTranscript((prev) => {
          const newTranscript = prev + final;
          console.log("ðŸ’¾ Transcription totale:", newTranscript);
          return newTranscript;
        });

        if (onTranscriptChange) {
          console.log("ðŸ”” Callback onTranscriptChange:", final.trim());
          onTranscriptChange(final.trim());
        }
      }
    };

    return () => {
      if (recognition && isListening) {
        recognition.stop();
      }
    };
  }, [lang, continuous, interimResults, isListening, onTranscriptChange, onError]);

  const startListening = useCallback(() => {
    const recognition = recognitionRef.current;
    if (!recognition || isListening) return;

    try {
      recognition.start();
    } catch (err) {
      console.error("Erreur dÃ©marrage reconnaissance:", err);
      setError("Impossible de dÃ©marrer la reconnaissance vocale");
    }
  }, [isListening]);

  const stopListening = useCallback(() => {
    const recognition = recognitionRef.current;
    if (!recognition) return;

    // ðŸ”§ FIX: Mettre isListening Ã  false AVANT d'arrÃªter pour Ã©viter le redÃ©marrage auto
    setIsListening(false);

    try {
      recognition.stop();
    } catch (err) {
      console.error("Erreur arrÃªt reconnaissance:", err);
    }
  }, []);

  const resetTranscript = useCallback(() => {
    setInterimTranscript("");
    setFinalTranscript("");
    setError(null);
  }, []);

  return {
    interimTranscript,
    finalTranscript,
    isListening,
    error,
    isSupported,
    startListening,
    stopListening,
    resetTranscript,
  };
}
