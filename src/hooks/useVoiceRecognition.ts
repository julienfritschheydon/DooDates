/**
 * Hook pour la reconnaissance vocale avec Web Speech API
 * Permet de transcrire la voix en texte pour le chat
 */

import { useState, useEffect, useRef, useCallback } from "react";
import { logger } from "../lib/logger";
import { ErrorFactory, logError } from "../lib/error-handling";
import { VOICE_RECOGNITION_CONFIG } from "../config/voiceRecognition.config";

// Types pour Web Speech API (non inclus dans TypeScript par dÃ©faut)
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  abort(): void;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null;
}

interface SpeechRecognitionConstructor {
  new (): SpeechRecognition;
}

declare global {
  interface Window {
    SpeechRecognition: SpeechRecognitionConstructor;
    webkitSpeechRecognition: SpeechRecognitionConstructor;
  }
}

export interface VoiceRecognitionState {
  /** Texte transcrit en cours (interim) */
  interimTranscript: string;
  /** Texte transcrit final */
  finalTranscript: string;
  /** Est en train d'Ã©couter */
  isListening: boolean;
  /** Erreur Ã©ventuelle */
  error: string | null;
  /** API supportÃ©e par le navigateur */
  isSupported: boolean;
}

export interface VoiceRecognitionActions {
  /** DÃ©marrer l'Ã©coute */
  startListening: () => void;
  /** ArrÃªter l'Ã©coute */
  stopListening: () => void;
  /** RÃ©initialiser la transcription */
  resetTranscript: () => void;
}

export interface UseVoiceRecognitionOptions {
  /** Langue de reconnaissance (dÃ©faut: 'fr-FR') */
  lang?: string;
  /** RÃ©sultats intermÃ©diaires (dÃ©faut: true) */
  interimResults?: boolean;
  /** Ã‰coute continue (dÃ©faut: false) */
  continuous?: boolean;
  /** Callback quand transcription finale */
  onTranscriptChange?: (transcript: string) => void;
  /** Callback quand erreur */
  onError?: (error: string) => void;
}

/**
 * Hook pour utiliser la reconnaissance vocale
 */
export function useVoiceRecognition(
  options: UseVoiceRecognitionOptions = {},
): VoiceRecognitionState & VoiceRecognitionActions {
  const {
    lang = "fr-FR",
    interimResults = true,
    continuous = false,
    onTranscriptChange,
    onError,
  } = options;

  const [isSupported, setIsSupported] = useState(false);
  const [isListening, setIsListening] = useState(false);
  const [finalTranscript, setFinalTranscript] = useState("");
  const [interimTranscript, setInterimTranscript] = useState("");
  const [error, setError] = useState<string | null>(null);
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const finalTranscriptRef = useRef<string>(""); // Ref pour persister entre les sessions
  const onTranscriptChangeRef = useRef(onTranscriptChange);
  const onErrorRef = useRef(onError);

  // Mettre Ã  jour les refs quand les callbacks changent
  useEffect(() => {
    onTranscriptChangeRef.current = onTranscriptChange;
    onErrorRef.current = onError;
  }, [onTranscriptChange, onError]);

  useEffect(() => {
    const SpeechRecognitionAPI = window.SpeechRecognition || window.webkitSpeechRecognition;

    if (SpeechRecognitionAPI) {
      setIsSupported(true);
      recognitionRef.current = new SpeechRecognitionAPI();
    } else {
      setIsSupported(false);
      console.warn("Web Speech API non supportÃ©e par ce navigateur");
    }
  }, []);

  // Configurer la reconnaissance vocale
  useEffect(() => {
    const recognition = recognitionRef.current;
    if (!recognition) return;

    recognition.continuous = continuous;
    recognition.interimResults = interimResults;
    recognition.lang = lang;

    recognition.onstart = () => {
      setIsListening(true);
      setError(null);
    };

    recognition.onend = () => {
      // Configuration stable : PAS de redÃ©marrage automatique
      // Voir voiceRecognition.config.ts pour l'explication
      if (VOICE_RECOGNITION_CONFIG.autoRestart && continuous && isListening) {
        console.log("ðŸ”„ RedÃ©marrage automatique...");
        setTimeout(() => {
          try {
            recognition.start();
          } catch (error) {
            logError(
              ErrorFactory.api(
                `Impossible de redÃ©marrer la reconnaissance vocale: ${error}`,
                "Erreur lors du redÃ©marrage automatique",
              ),
              { component: "voice-recognition", operation: "auto-restart" },
            );
            setIsListening(false);
          }
        }, VOICE_RECOGNITION_CONFIG.restartDelay);
      } else {
        setIsListening(false);
      }
    };

    recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      logError(
        ErrorFactory.api(
          `Erreur reconnaissance vocale: ${event.error}`,
          "Erreur de reconnaissance",
        ),
        { metadata: { errorType: event.error } },
      );

      // Ignorer l'erreur "no-speech" (silence normal, pas une vraie erreur)
      if (event.error === "no-speech") {
        console.log("â¸ï¸ Silence dÃ©tectÃ©, arrÃªt normal");
        return;
      }

      let errorMessage = "Erreur de reconnaissance vocale";

      switch (event.error) {
        case "no-speech":
          errorMessage = "Aucune parole dÃ©tectÃ©e";
          break;
        case "audio-capture":
          errorMessage = "Microphone non accessible";
          break;
        case "not-allowed":
          errorMessage = "Permission microphone refusÃ©e";
          break;
        case "network":
          errorMessage = "Erreur rÃ©seau";
          break;
        case "aborted":
          errorMessage = "Reconnaissance interrompue";
          break;
        default:
          errorMessage = `Erreur: ${event.error}`;
      }

      setError(errorMessage);
      setIsListening(false);

      if (onErrorRef.current) {
        onErrorRef.current(errorMessage);
      }
    };

    recognition.onresult = (event: SpeechRecognitionEvent) => {
      // ðŸ”§ FIX: Exactement comme remarkablemark
      // Boucler depuis resultIndex (pas depuis 0)
      let finalText = "";
      let interimText = "";

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;

        if (event.results[i].isFinal) {
          finalText += transcript;
        } else {
          interimText += transcript;
        }
      }

      // Accumuler les rÃ©sultats finaux avec la ref
      if (finalText) {
        finalTranscriptRef.current += finalText + " ";
        setFinalTranscript(finalTranscriptRef.current);
        if (onTranscriptChangeRef.current) {
          onTranscriptChangeRef.current(finalText);
        }
      }

      setInterimTranscript(interimText);
    };

    return () => {
      if (recognition && isListening) {
        recognition.stop();
      }
    };
  }, [lang, continuous, interimResults, isListening]);
  // onTranscriptChange et onError sont dans des refs, pas besoin de les mettre en dÃ©pendances

  const startListening = useCallback(() => {
    const recognition = recognitionRef.current;
    if (!recognition || isListening) return;

    // NE PAS rÃ©initialiser - on veut accumuler entre les sessions
    // setFinalTranscript("");
    // setInterimTranscript("");

    try {
      recognition.start();
    } catch (err: any) {
      // Ignorer l'erreur si dÃ©jÃ  dÃ©marrÃ©
      if (err.message?.includes("already started")) {
        console.log("âš ï¸ Reconnaissance dÃ©jÃ  active");
        return;
      }

      logError(
        ErrorFactory.api("Erreur dÃ©marrage reconnaissance vocale", "Impossible de dÃ©marrer"),
        { metadata: { error: err } },
      );
      setError("Impossible de dÃ©marrer la reconnaissance vocale");
    }
  }, [isListening]);

  const stopListening = useCallback(() => {
    const recognition = recognitionRef.current;
    if (!recognition) return;

    // ðŸ”§ FIX: Mettre isListening Ã  false AVANT d'arrÃªter pour Ã©viter le redÃ©marrage auto
    setIsListening(false);

    try {
      recognition.stop();
    } catch (err) {
      logError(ErrorFactory.api("Erreur arrÃªt reconnaissance vocale", "Impossible d'arrÃªter"), {
        metadata: { error: err },
      });
    }
  }, []);

  const resetTranscript = useCallback(() => {
    finalTranscriptRef.current = "";
    setInterimTranscript("");
    setFinalTranscript("");
    setError(null);
  }, []);

  return {
    interimTranscript,
    finalTranscript,
    isListening,
    error,
    isSupported,
    startListening,
    stopListening,
    resetTranscript,
  };
}
